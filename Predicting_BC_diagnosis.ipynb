{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3609588",
   "metadata": {},
   "source": [
    "## Libraries Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96854638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592d400",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448d023e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>...</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   texture_mean  perimeter_mean  smoothness_mean  compactness_mean  \\\n",
       "0         10.38          122.80          0.11840           0.27760   \n",
       "1         17.77          132.90          0.08474           0.07864   \n",
       "2         21.25          130.00          0.10960           0.15990   \n",
       "3         20.38           77.58          0.14250           0.28390   \n",
       "4         14.34          135.10          0.10030           0.13280   \n",
       "\n",
       "   concavity_mean  concave points_mean  symmetry_mean  fractal_dimension_mean  \\\n",
       "0          0.3001              0.14710         0.2419                 0.07871   \n",
       "1          0.0869              0.07017         0.1812                 0.05667   \n",
       "2          0.1974              0.12790         0.2069                 0.05999   \n",
       "3          0.2414              0.10520         0.2597                 0.09744   \n",
       "4          0.1980              0.10430         0.1809                 0.05883   \n",
       "\n",
       "   radius_se  texture_se  ...  fractal_dimension_se  texture_worst  \\\n",
       "0     1.0950      0.9053  ...              0.006193          17.33   \n",
       "1     0.5435      0.7339  ...              0.003532          23.41   \n",
       "2     0.7456      0.7869  ...              0.004571          25.53   \n",
       "3     0.4956      1.1560  ...              0.009208          26.50   \n",
       "4     0.7572      0.7813  ...              0.005115          16.67   \n",
       "\n",
       "   perimeter_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0           184.60            0.1622             0.6656           0.7119   \n",
       "1           158.80            0.1238             0.1866           0.2416   \n",
       "2           152.50            0.1444             0.4245           0.4504   \n",
       "3            98.87            0.2098             0.8663           0.6869   \n",
       "4           152.20            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "0                0.2654          0.4601                  0.11890   \n",
       "1                0.1860          0.2750                  0.08902   \n",
       "2                0.2430          0.3613                  0.08758   \n",
       "3                0.2575          0.6638                  0.17300   \n",
       "4                0.1625          0.2364                  0.07678   \n",
       "\n",
       "   diagnosis_encoded  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/final_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052b01b9",
   "metadata": {},
   "source": [
    "## Split Data (Target, Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173a7456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (569, 24)\n",
      "Target shape: (569,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('diagnosis_encoded',axis=1)\n",
    "print('Features shape:',X.shape)\n",
    "y= df['diagnosis_encoded']\n",
    "print('Target shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4d8c4e",
   "metadata": {},
   "source": [
    "## Split Data (Train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d1ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (455, 24)\n",
      "X_test shape: (114, 24)\n",
      "y_train shape: (455,)\n",
      "y_test shape: (114,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=42)\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('y_train shape:',y_train.shape)\n",
    "print('y_test shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d25bab",
   "metadata": {},
   "source": [
    "## Data scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83183310",
   "metadata": {},
   "source": [
    "Since our dataset includes measurements with different ranges, like radius, texture, perimeter, and area. Standardizing these values will ensure that each feature contributes more equally to the model's training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c324861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training dataset and transform it\n",
    "\n",
    "X_training_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# transform the testing data\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a60c1",
   "metadata": {},
   "source": [
    "## Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fc50d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "\n",
    "model = LogisticRegression(max_iter=500)\n",
    "\n",
    "#Fit the data to the model\n",
    "\n",
    "model.fit(X_training_scaled,y_train)\n",
    "\n",
    "# make prediction using X_test\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6ca0812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# check accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f31662e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        71\n",
      "           1       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8e742",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "581a2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "\n",
    "model2 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Fit the data to the model\n",
    "\n",
    "model2.fit(X_training_scaled,y_train)\n",
    "\n",
    "# make prediction using X_test\n",
    "\n",
    "y_pred2 = model2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf0865c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred2)\n",
    "print(f\"Model accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b025f01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        71\n",
      "           1       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6fe993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
